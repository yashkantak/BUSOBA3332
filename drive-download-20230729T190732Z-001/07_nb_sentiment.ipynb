{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Sentiment (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make this notebook's output stable across runs\n",
    "random_state = 1\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# Options for plots\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.labelpad'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load IMDB Movie Reviews\n",
    "\n",
    "Source: http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = 'https://raw.githubusercontent.com/natecraig/aiml/main/Data/movie_train.txt'\n",
    "test_url = 'https://raw.githubusercontent.com/natecraig/aiml/main/Data/movie_test.txt'\n",
    "\n",
    "train_download = requests.get(train_url).content\n",
    "test_download = requests.get(test_url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For train and test sets, the first 12,500 reviews are positive,\n",
    "# and the second 12,500 reviews are negative\n",
    "\n",
    "X_train_raw = []\n",
    "for l in io.StringIO(train_download.decode('utf-8')):\n",
    "    X_train_raw.append(l.strip())\n",
    "    \n",
    "X_test_raw = []\n",
    "for l in io.StringIO(test_download.decode('utf-8')):\n",
    "    X_test_raw.append(l.strip())\n",
    "    \n",
    "categories = ['Negative', 'Positive']\n",
    "y = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was a must see documentary for me when I missed the opportunity in 2004, so I was definitely going to watch the repeat. I really sympathised with the main character of the film, because, this is true, I have a milder condition of the skin problem he had, Dystrophic Epidermolysis Bullosa (EB). This is a sad, sometimes amusing and very emotional documentary about a boy with a terrible skin disorder. Jonny Kennedy speaks like a kid (because of wasting vocal muscle) and never went through puberty, but he is 36 years old. Most sympathising moments are seeing his terrible condition, and pealing off his bandages. Jonny had quite a naughty sense of humour, he even narrated from beyond the grave when showing his body in a coffin. He tells his story with the help of his mother, Edna Kennedy, his older brother and celebrity model, and Jonny's supporter, Nell McAndrew. It won the BAFTAs for Best Editing and Best New Director (Factual), and it was nominated for Best Sound (Factual) and the Flaherty Documentary Award. It was number 10 on The 100 Greatest TV Treats 2004. A must see documentary!\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y[20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie tries hard, but completely lacks the fun of the 1960s TV series, that I am sure people do remember with fondness. Although I am 17, I watched some of the series on YouTube a long time ago and it was enjoyable and fun. Sadly, this movie does little justice to the series.<br /><br />The special effects are rather substandard, and this wasn't helped by the flat camera-work. The script also was dull and lacked any sense of wonder and humour. Other films with under-par scripting are Home Alone 4, Cat in the Hat, Thomas and the Magic Railroad and Addams Family Reunion.<br /><br />Now I will say I liked the idea of the story, but unfortunately it was badly executed and ran out of steam far too early, and I am honestly not sure for this reason this is something for the family to enjoy. And I was annoyed by the talking suit, despite spirited voice work from Wayne Knight.<br /><br />But the thing that angered me most about this movie was that it wasted the talents of Christopher Lloyd, Jeff Daniels and Daryl Hannah, all very talented actors. Jeff Daniels has pulled off some good performances before, but he didn't seem to have a clue what he was supposed to be doing, and Elizabeth Hurley's character sadly came across as useless. Daryl Hannah is a lovely actress and generally ignored, and I liked the idea of her being the love interest, but sadly you see very little of her,(not to mention the Monster attack is likely to scare children than enthrall them) likewise with Wallace Shawn as some kind of government operative. Christopher Lloyd acquits himself better, and as an actor I like Lloyd a lot(he was in two of my favourite films Clue and Who Framed Roger Rabbit, and I am fond of Back To The Future) but he was given little to work with, and had a tendency to overact quite wildly.<br /><br />Overall, as much I wanted to like this movie, I was left unimpressed. Instead of being fun, it came across as pointless, and that is a shame because it had a lot of potential, with some talented actors and a good idea, but wasted with poor execution. 1/10 Bethany Cox\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw[20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop HTML line breaks\n",
    "regex = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "X_train_raw = [regex.sub(' ', x) for x in X_train_raw]\n",
    "X_test_raw = [regex.sub(' ', x) for x in X_test_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie tries hard, but completely lacks the fun of the 1960s TV series, that I am sure people do remember with fondness. Although I am 17, I watched some of the series on YouTube a long time ago and it was enjoyable and fun. Sadly, this movie does little justice to the series. The special effects are rather substandard, and this wasn't helped by the flat camera work. The script also was dull and lacked any sense of wonder and humour. Other films with under par scripting are Home Alone 4, Cat in the Hat, Thomas and the Magic Railroad and Addams Family Reunion. Now I will say I liked the idea of the story, but unfortunately it was badly executed and ran out of steam far too early, and I am honestly not sure for this reason this is something for the family to enjoy. And I was annoyed by the talking suit, despite spirited voice work from Wayne Knight. But the thing that angered me most about this movie was that it wasted the talents of Christopher Lloyd, Jeff Daniels and Daryl Hannah, all very talented actors. Jeff Daniels has pulled off some good performances before, but he didn't seem to have a clue what he was supposed to be doing, and Elizabeth Hurley's character sadly came across as useless. Daryl Hannah is a lovely actress and generally ignored, and I liked the idea of her being the love interest, but sadly you see very little of her,(not to mention the Monster attack is likely to scare children than enthrall them) likewise with Wallace Shawn as some kind of government operative. Christopher Lloyd acquits himself better, and as an actor I like Lloyd a lot(he was in two of my favourite films Clue and Who Framed Roger Rabbit, and I am fond of Back To The Future) but he was given little to work with, and had a tendency to overact quite wildly. Overall, as much I wanted to like this movie, I was left unimpressed. Instead of being fun, it came across as pointless, and that is a shame because it had a lot of potential, with some talented actors and a good idea, but wasted with poor execution. 1 10 Bethany Cox\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw[20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features Using Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvect = CountVectorizer()\n",
    "X_train_count = countvect.fit_transform(X_train_raw)\n",
    "X_test_count = countvect.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 74849)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bromwell', 9251)\n",
      "('high', 30902)\n",
      "('is', 34585)\n",
      "('cartoon', 10850)\n",
      "('comedy', 13498)\n",
      "('it', 34683)\n",
      "('ran', 53427)\n",
      "('at', 4753)\n",
      "('the', 66339)\n",
      "('same', 57283)\n"
     ]
    }
   ],
   "source": [
    "# The vocabulary dictionary records the index of each word's feature\n",
    "# Print 10 example entries\n",
    "for idx, (k, v) in enumerate(countvect.vocabulary_.items()):\n",
    "    if idx == 10: break\n",
    "    print((k, v))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me:           41798\n",
      "the:          66339\n",
      "and:          3258\n",
      "popcorn:      50824\n",
      "scary:        57836\n",
      "fun:          26333\n",
      "tom:          67237\n",
      "cruise:       15792\n",
      "will:         73091\n",
      "ferrell:      24285\n",
      "ferrel:       24284\n",
      "disney:       18936\n",
      "elsa:         21403\n",
      "timon:        66964\n"
     ]
    }
   ],
   "source": [
    "# Find the location of these example words\n",
    "example_words = ['me', 'the', 'and',\n",
    "                 'popcorn', 'scary', 'fun',\n",
    "                 'tom', 'cruise', 'will', 'ferrell', 'ferrel',      \n",
    "                 'disney', 'elsa', 'timon']\n",
    "\n",
    "for word in example_words:\n",
    "    print(f'{word + \":\":14}{countvect.vocabulary_[word]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Naive Bayes Model to Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbclf = MultinomialNB()\n",
    "nbclf.fit(X_train_count, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.93      0.90     12500\n",
      "    Positive       0.93      0.86      0.89     12500\n",
      "\n",
      "    accuracy                           0.90     25000\n",
      "   macro avg       0.90      0.90      0.90     25000\n",
      "weighted avg       0.90      0.90      0.90     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get performance on training data\n",
    "print(classification_report(y, nbclf.predict(X_train_count),\n",
    "                            target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.78      0.88      0.83     12500\n",
      "    Positive       0.86      0.75      0.80     12500\n",
      "\n",
      "    accuracy                           0.81     25000\n",
      "   macro avg       0.82      0.81      0.81     25000\n",
      "weighted avg       0.82      0.81      0.81     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get performance on test data\n",
    "print(classification_report(y, nbclf.predict(X_test_count),\n",
    "                            target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features Using TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_count)\n",
    "X_test_tfidf = tfidf.transform(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 74349)\t0.05206888010010324\n",
      "  (0, 74158)\t0.055050768098681556\n",
      "  (0, 72911)\t0.061112244873247706\n",
      "  (0, 72904)\t0.033681880397817464\n",
      "  (0, 72773)\t0.04128496380247337\n",
      "  (0, 72753)\t0.03797512811718631\n",
      "  (0, 72703)\t0.03617656837997499\n",
      "  (0, 72544)\t0.10903604567212596\n",
      "  (0, 68145)\t0.0859738287067699\n",
      "  (0, 67125)\t0.05584454818700603\n",
      "  (0, 66925)\t0.0386085227347137\n",
      "  (0, 66699)\t0.053325764053003\n",
      "  (0, 66526)\t0.04751002409485954\n",
      "  (0, 66367)\t0.07247542780430569\n",
      "  (0, 66339)\t0.06066862820581213\n",
      "  (0, 66322)\t0.054204063816507164\n",
      "  (0, 66299)\t0.042450397436525476\n",
      "  (0, 65750)\t0.12716378450734914\n",
      "  (0, 65748)\t0.3115242868369409\n",
      "  (0, 64683)\t0.10625234549709642\n",
      "  (0, 64115)\t0.05319903669985538\n",
      "  (0, 63768)\t0.1749891196225475\n",
      "  (0, 63767)\t0.16908507449768323\n",
      "  (0, 61617)\t0.03673963173839623\n",
      "  (0, 60495)\t0.08891486418508797\n",
      "  :\t:\n",
      "  (0, 32729)\t0.09506058762703333\n",
      "  (0, 30902)\t0.17694132818362251\n",
      "  (0, 30670)\t0.05165066420396213\n",
      "  (0, 24623)\t0.1460232241180382\n",
      "  (0, 24328)\t0.12291687653693922\n",
      "  (0, 23785)\t0.06174237795752139\n",
      "  (0, 23124)\t0.07813985916392845\n",
      "  (0, 22218)\t0.07966085407072616\n",
      "  (0, 19854)\t0.05806734930638608\n",
      "  (0, 13498)\t0.06327633798098768\n",
      "  (0, 12935)\t0.11054994223998137\n",
      "  (0, 12676)\t0.0710874250773169\n",
      "  (0, 10850)\t0.09820830187522603\n",
      "  (0, 10357)\t0.0367865082109835\n",
      "  (0, 9765)\t0.11837846205999199\n",
      "  (0, 9251)\t0.42739545765320475\n",
      "  (0, 6720)\t0.06446373458925247\n",
      "  (0, 4753)\t0.05284074007642992\n",
      "  (0, 4465)\t0.045848556762081015\n",
      "  (0, 3258)\t0.019458982767218594\n",
      "  (0, 2662)\t0.031003250667925298\n",
      "  (0, 2155)\t0.07991062417997415\n",
      "  (0, 1919)\t0.10020244271216187\n",
      "  (0, 1277)\t0.03515947912613814\n",
      "  (0, 646)\t0.12349596656053656\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Naive Bayes Model to TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbclf = MultinomialNB()\n",
    "nbclf.fit(X_train_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.93      0.91     12500\n",
      "    Positive       0.93      0.89      0.91     12500\n",
      "\n",
      "    accuracy                           0.91     25000\n",
      "   macro avg       0.91      0.91      0.91     25000\n",
      "weighted avg       0.91      0.91      0.91     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get performance on training data\n",
    "print(classification_report(y, nbclf.predict(X_train_tfidf),\n",
    "                            target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.89      0.84     12500\n",
      "    Positive       0.88      0.78      0.82     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.84      0.83      0.83     25000\n",
      "weighted avg       0.84      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get performance on test data\n",
    "print(classification_report(y, nbclf.predict(X_test_tfidf),\n",
    "                            target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use nGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1771985)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "X_train_count = countvect.fit_transform(X_train_raw)\n",
    "X_train_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good movie:       669449\n",
      "bad movie:        120741\n",
      "silly plot:       1421010\n",
      "crazy action:     345009\n",
      "buttered popcorn: 207145\n"
     ]
    }
   ],
   "source": [
    "# Find the location of example ngrams\n",
    "example_words = ['good movie', 'bad movie',\n",
    "                 'silly plot', 'crazy action',\n",
    "                 'buttered popcorn']\n",
    "\n",
    "for word in example_words:\n",
    "    print(f'{word + \":\":18}{countvect.vocabulary_[word]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "    ('nbclf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;nbclf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;nbclf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('nbclf', MultinomialNB())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_raw, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      0.99      0.98     12500\n",
      "    Positive       0.99      0.98      0.98     12500\n",
      "\n",
      "    accuracy                           0.98     25000\n",
      "   macro avg       0.98      0.98      0.98     25000\n",
      "weighted avg       0.98      0.98      0.98     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get performance on training data\n",
    "print(classification_report(y, clf.predict(X_train_raw),\n",
    "                            target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.89      0.86     12500\n",
      "    Positive       0.88      0.82      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.86      0.85      0.85     25000\n",
      "weighted avg       0.86      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get performance on test data\n",
    "print(classification_report(y, clf.predict(X_test_raw),\n",
    "                            target_names=categories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
