{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cfd8eb-49f7-4ac2-b982-c915a1021f28",
   "metadata": {},
   "source": [
    "# Translation (Encoder-Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "warming-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import absl.logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Restrict tensorflow output to errors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "# Make this notebook's output stable across runs\n",
    "random_state = 1000\n",
    "np.random.seed(random_state)\n",
    "tf.random.set_seed(random_state)\n",
    "\n",
    "# Plot formatting\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74a266c-a6a3-437f-b792-2b6d8309bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
    "path = tf.keras.utils.get_file('spa-eng.zip', origin=url, cache_dir='datasets',\n",
    "                               extract=True)\n",
    "text = (Path(path).with_name('spa-eng') / 'spa.txt').read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b27393-0f8d-4866-a6e5-fffa3f6d63a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('¡', '').replace('¿', '')\n",
    "pairs = [line.split('\\t') for line in text.splitlines()]\n",
    "np.random.shuffle(pairs)\n",
    "# Separate the pairs into separate lists\n",
    "sentences_en, sentences_es = zip(*pairs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba987519-deee-4656-b7e4-14ffe980628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Those are our teachers' cars. => Esos son los autos de nuestros profesores.\n",
      "Tom told us you were Canadian, too. => Tom nos dijo que tú también eras canadiense.\n",
      "Many trains pass through the old stone tunnel. => Muchos trenes atraviesan el viejo túnel de piedra.\n",
      "Tom remembered all the details. => Tom recordó todos los detalles.\n",
      "I need a lamp. => Yo necesito una lámpara.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(sentences_en[i], '=>', sentences_es[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef83b48a-d7b2-4b9e-8c94-451290981717",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "max_length = 50\n",
    "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_en.adapt(sentences_en)\n",
    "text_vec_layer_es.adapt([f'startofseq {s} endofseq' for s in sentences_es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ebd313-cf64-45c8-8fa1-dccd986608eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 'is', 'he']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_en.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de40e3e-a245-4d0a-8f8a-4b019b058361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'a', 'no', 'tom', 'la']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_es.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f1767-ac76-4dc6-ae52-61be24e7d582",
   "metadata": {},
   "source": [
    "## Fit an Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892e6390-9b51-4096-bdb2-f0a2e9a086d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.constant(sentences_en[:100_000])\n",
    "X_valid = tf.constant(sentences_en[100_000:])\n",
    "X_train_dec = tf.constant([f'startofseq {s}' for s in sentences_es[:100_000]])\n",
    "X_valid_dec = tf.constant([f'startofseq {s}' for s in sentences_es[100_000:]])\n",
    "Y_train = text_vec_layer_es([f'{s} endofseq' for s in sentences_es[:100_000]])\n",
    "Y_valid = text_vec_layer_es([f'{s} endofseq' for s in sentences_es[100_000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7adb9ec1-fb57-4d2b-b647-1c793758dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1faf573f-d5f3-443f-87ce-d870c9350a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
    "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    "                                                    mask_zero=True)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    "                                                    mask_zero=True)\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5c7a3f-cc1f-4230-aa07-4f509d08fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf83d6c5-9cd9-46c9-b53a-198775ef6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2505516e-42a3-405f-bce9-bcf277670eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "Y_proba = output_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ef207-bd47-45df-8ef5-c78cf9f9ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3125/3125 [==============================] - 881s 281ms/step - loss: 2.9273 - accuracy: 0.4269 - val_loss: 2.1594 - val_accuracy: 0.5246\n",
      "Epoch 2/3\n",
      "1858/3125 [================>.............] - ETA: 5:17 - loss: 1.9364 - accuracy: 0.5611"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit((X_train, X_train_dec), Y_train, epochs=3,\n",
    "          validation_data=((X_valid, X_valid_dec), Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c74e0-78ac-4ea9-8891-b4c8667de61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('translation', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ca11c-8d7e-4223-953d-e1cda6b9dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('translation')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17889c60-fc7f-4989-8f88-99a1301cafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence_en):\n",
    "    translation = ''\n",
    "    for word_idx in range(max_length):\n",
    "        X = np.array([sentence_en])  # encoder input \n",
    "        X_dec = np.array(['startofseq ' + translation])  # decoder input\n",
    "        y_proba = model.predict((X, X_dec))[0, word_idx]  # last token's probas\n",
    "        predicted_word_id = np.argmax(y_proba)\n",
    "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
    "        if predicted_word == 'endofseq':\n",
    "            break\n",
    "        translation += ' ' + predicted_word\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e801b9f-b615-4cbc-a2ab-b4bb7fbbd97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('I like soccer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11818478-b042-4045-9096-131dda428518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
