{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "758ff223-c147-4954-8975-2cdbfcf66fa9",
   "metadata": {},
   "source": [
    "# Hugging Face for Text Generation\n",
    "\n",
    "See [this overview](https://huggingface.co/course/chapter1/1) for an introduction to Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c09c68-10d1-48bc-b753-ce387c25edb8",
   "metadata": {},
   "source": [
    "## Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb43c842-79b3-4cd1-9ecb-71ed5ed4a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to run the following command to install Hugging Face\n",
    "# !pip install transformers\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc846781-0012-4090-b33f-4ebdce5e84cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712424e5e7864e88a8b8e5d9df04f2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbee08b1947489898fbd6628b163a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94ef96620b34940b59fb0ffad8d68fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af5d5d245ef470583ccc2be31436140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ac56d90b424fb88f3d7aaca12c64f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Add the EOS token as a PAD token to avoid warnings\n",
    "model = TFGPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadcf9e9-d0fe-4f97-9bd6-7f5745a0d666",
   "metadata": {},
   "source": [
    "## Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "719ba06e-fc20-492f-b2bd-b69b87393a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode our input\n",
    "input_ids = tokenizer.encode('I enjoy coffee in the morning', return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d8c37fa-cddb-41e4-a27b-d377f91ebb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[  40, 2883, 6891,  287,  262, 3329]], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View input vocabulary indices\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ec30411-00d1-4310-aff9-0ee037976355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy coffee in the morning, but I'm not a fan of coffee in the evening.\n"
     ]
    }
   ],
   "source": [
    "# Generate tokens using token-by-token maximum probabilities (a \"greedy\" approach)\n",
    "greedy_output = model.generate(input_ids, early_stopping=True, max_length=19)\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1293e59f-1e67-4b5b-bef1-5c33bd7a1dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy coffee in the morning, but I don't like coffee in the evening.\n"
     ]
    }
   ],
   "source": [
    "# Generate tokens using beam search, a heuristic that looks for likely sequences\n",
    "output = model.generate(input_ids, max_length=17, num_beams=5, early_stopping=True)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec9d284c-34d0-4a12-8546-95f28cb7823a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy coffee in the morning, but I don't like to spend time with my friends and family. I'm not one of those people who likes to spend time with my kids. I like to spend time with my family and friends. I like\n"
     ]
    }
   ],
   "source": [
    "# Generate with random sampling\n",
    "sample_output = model.generate(input_ids, do_sample=True, max_length=50, \n",
    "                               top_k=0, temperature=0.5)\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20513e4d-4cb9-4206-92d6-6930f131eef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy coffee in the morning and on the evening, on the weekends, or on weekends in particular,\" she told Crain's. \"The fact that we're part of this industry brings a huge potential market of consumers that we don't have access\n"
     ]
    }
   ],
   "source": [
    "# Use top K sampling\n",
    "k_sample_output = model.generate(input_ids, do_sample=True, max_length=50, \n",
    "                               top_k=50)\n",
    "\n",
    "print(tokenizer.decode(k_sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cdc058e6-bde5-4558-8fad-e2f179ea19d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy coffee in the morning. You just need to focus on the task at hand, as much as possible. Nothing will stop you from getting back in the spirit.\n",
      "\n",
      "I also don't like drinking – I hate it.\n",
      "\n",
      "Whatever\n"
     ]
    }
   ],
   "source": [
    "# Use top p sampling\n",
    "p_sample_output = model.generate(input_ids, do_sample=True, max_length=50,\n",
    "                                 top_p=0.9, top_k=0)\n",
    "\n",
    "print(tokenizer.decode(p_sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd8bc48-3f0c-4063-b3a1-cf5ba69934e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
